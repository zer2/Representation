{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5a51050",
   "metadata": {},
   "source": [
    "# 1. Intro\n",
    "\n",
    "In terms of ethnic bakground, which US states are the most representative of the entire country?\n",
    "\n",
    "It is easy enough to get data on the ethnic makeup of U.S. states and make a simple ranking. However, all of the obvious metrics I thought of had some kind of flaw in this context, which made me feel uneasy about using them. This begged the question: is there an alternative metric, better suited for this particular task?\n",
    "\n",
    "I believe that there is. The goal of this notebook is to formulate this new metric, and investigate its properties\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1dd614d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats.stats import pearsonr   \n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b60e252",
   "metadata": {},
   "source": [
    "Let's start by grabbing our data, which was acquired from [the internet](https://www.kff.org/other/state-indicator/distribution-by-raceethnicity/?currentTimeframe=0&sortModel=%7B%22colId%22:%22Location%22,%22sort%22:%22asc%22%7D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02915d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../raw_data.csv', skiprows = 2)\n",
    "df = df.set_index('Location').drop(columns = ['Total','Footnotes'])\n",
    "\n",
    "for col in df.columns:\n",
    "    df[col] = pd.to_numeric(df[col],errors = 'coerce').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b6566eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            White  Black  Hispanic  Asian  American Indian/Alaska Native  \\\n",
      "Location                                                                   \n",
      "Alabama     0.654  0.265     0.044  0.014                          0.004   \n",
      "Alaska      0.600  0.022     0.070  0.060                          0.151   \n",
      "Arizona     0.542  0.043     0.318  0.033                          0.039   \n",
      "Arkansas    0.721  0.152     0.078  0.016                          0.006   \n",
      "California  0.364  0.053     0.395  0.147                          0.004   \n",
      "\n",
      "            Native Hawaiian/Other Pacific Islander  Multiple Races  \n",
      "Location                                                            \n",
      "Alabama                                      0.000           0.019  \n",
      "Alaska                                       0.015           0.083  \n",
      "Arizona                                      0.002           0.024  \n",
      "Arkansas                                     0.004           0.024  \n",
      "California                                   0.004           0.033  \n",
      "[0.601 0.122 0.185 0.056 0.007 0.002 0.028]\n"
     ]
    }
   ],
   "source": [
    "df_country_values = df[df.index == 'United States'].values[0]\n",
    "df_states = df[df.index != 'United States']\n",
    "print(df_states.head())\n",
    "print(df_country_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9dc001",
   "metadata": {},
   "source": [
    "# 2. Simple rankings\n",
    "\n",
    "So we have our target numbers (the US population), and our candidate versions (the states). We want to rank the states in such a way that the highest-ranked states have distributions similar to the whole country. When quantifying similarity, a few metrics come to my mind immediately: MAE, MSE, and correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "009057d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "def make_comparisons(row):\n",
    "    #cosine_similarity = \n",
    "    mae = mean_absolute_error(row.values, df_country_values)\n",
    "    mse = mean_squared_error(row.values, df_country_values)\n",
    "    corr = pearsonr(row.values, df_country_values)[0]\n",
    "    return pd.Series([mae, mse, corr], index = ['mae','mse','corr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f964687f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zach Rosenof\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1787: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, val, pi)\n"
     ]
    }
   ],
   "source": [
    "df_states.loc[:,['mae','mse','corr']] = df_states.apply(make_comparisons, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2d2e7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n(df, metric, n):\n",
    "    return df.sort_values(metric, ascending = metric not in ['corr','log_loss']).index[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fd9fc30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Illinois</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>Illinois</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>Connecticut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Connecticut</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>New Jersey</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>New Jersey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>Rhode Island</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Florida</td>\n",
       "      <td>Florida</td>\n",
       "      <td>Colorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Delaware</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>Massachusetts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Rhode Island</td>\n",
       "      <td>Rhode Island</td>\n",
       "      <td>Kansas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Colorado</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>Nebraska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>North Carolina</td>\n",
       "      <td>Washington</td>\n",
       "      <td>Pennsylvania</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>Washington</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Washington</td>\n",
       "      <td>Delaware</td>\n",
       "      <td>Utah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>Oregon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Nevada</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>Arkansas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>Virginia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               mae             mse           corr\n",
       "0         Illinois        Illinois       Illinois\n",
       "1         New York        New York    Connecticut\n",
       "2      Connecticut     Connecticut       New York\n",
       "3       New Jersey      New Jersey     New Jersey\n",
       "4         Virginia        Virginia   Rhode Island\n",
       "5          Florida         Florida       Colorado\n",
       "6         Delaware        Colorado  Massachusetts\n",
       "7     Rhode Island    Rhode Island         Kansas\n",
       "8         Colorado  North Carolina       Nebraska\n",
       "9   North Carolina      Washington   Pennsylvania\n",
       "10   Massachusetts   Massachusetts     Washington\n",
       "11      Washington        Delaware           Utah\n",
       "12        Arkansas        Oklahoma         Oregon\n",
       "13          Nevada        Arkansas       Arkansas\n",
       "14    Pennsylvania          Nevada       Virginia"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'mae' : get_top_n(df_states,'mae',15), \n",
    "              'mse' : get_top_n(df_states,'mse',15), \n",
    "              'corr' : get_top_n(df_states,'corr',15)\n",
    "             })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fe8d93",
   "metadata": {},
   "source": [
    "We have some possible lists. However, do we really love any of these metrics for this task?\n",
    "\n",
    "MAE is interpretable, because we can think of it as the total fraction of the population which would have to change group in order for the distribution to match the target distribution. However, it has an undesirable property- it only cares about absolute difference, not percentage difference. So a 61% vs a 60% is punished as severely as a 5% vs a 4%. Intuitively, the 1% difference is more important to the smaller group, and the metric should take that into account.\n",
    "\n",
    "MSE has the same problem, except worse (by squaring the errors, it will tend to care even more about larger groups, which will tend to have larger errors). It is also not interpretable. MSE is used often because errors in the real world tend to have the normal distribution, but that does not really apply here. \n",
    "\n",
    "Correlation has the opposite problem. It gives every dimension equal weight, even the ones with very low values. We really shouldn't be caring as much about the group with 0.0001% population and 0.0001% variance as we are the group with 10% population and 10% variance. Plus, again, it isn't really interpretable. \n",
    "\n",
    "In addition to the aforementioned mundane problems, I feel like all these metrics also have a more fundamental problem. They all fail to take advantage of the unique nature of population data, which is that the fractions always sums to 1. The traditional metrics don't care about that and apply equally well to data with no specific sum. \n",
    "\n",
    "A natural question we might ask is, \"what is special about a list of numbers that add up to 1?\" My answer is that we can think of it as a probability distribution, and sample it. \n",
    "\n",
    "So... what if we did sample it? Perhaps we can choose N people from both candidate \"distribution\", and seeing how often it matches the target?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afc589e",
   "metadata": {},
   "source": [
    "# 3. A new approach\n",
    "\n",
    "Let's try this approach to rank two populations, Y and Z, on their similarity to X. Our first instict might be to need to run a bunch of experiments, choosing N people from each population and seeing whether Y or Z match X more often. However, there is an immediate problem: if a single population is 0 for Y or Z, but greater than 0 for X, the simulated population will never match. \n",
    "\n",
    "To get around the problem, we can change our experiment a little bit. Let's start with X and mix in an infinitesimal smidgeon of Y or Z, so that the distributions are close to the original ones, but moving slightly towards the others. Our problem statement changes to \"which population can be averaged with the original distribution, and cause the least distortion in overall sample probabilities?\" We will start with a weighted average between X and the other distribution, then later take the limit as the weighted average shifts towards X.\n",
    "\n",
    "The probability of the Y distribution matching the original is $ n_c *  \\Pi^{i=j}_{i=1} ((1-w)x_i + wy_i)^{x_i*n} $ where $x_i$ is the proportion of X which is group i, $y_i$ is the proportion of Y which is group i, $j$ is the number of groups within the population, $w$ is the weight of the Y distribution, $n$ is the number of draws we are making, and $n_c$ is the number of ways of combining draws to match the exact population (e.g. if X has two 50-50 groups and n is two, the \"true\" distribution can be A-B or B-A and $n_c = 2$. With a higher value of $n$, $n_c$ will become a very large number). Here we are assuming that $x_i*n$ is always an integer, which is essentially true when we bring n to infinity. Also, this equation applies equally well to Z instead of Y\n",
    "\n",
    "Without loss of generality, we can take the log and remove the constants. After all, we are only interested in which distribution is more likely, not exactly how likely either is. This reduces to $\\sum^{i=j}_{i=1} x_i * log((1-w)x + wy)$\n",
    "\n",
    "Now we want to take the limit as $w$ approaches 0. If we apply that directly, we get $\\sum^{i=j}_{i=1} x_i * log(x_i)$, which does not help us because it is always the same. \n",
    "\n",
    "Fortunately we can also look at derivates. If the first derivative is higher for one distribution than the other, then for the smallest infinitesimal $w$ we can look at, the distribution's score will be higher. Taking the first derivative we get\n",
    "$\\sum^{i=j}_{i=1} \\frac{x(y-x)}{-wx+wy+x}$. Taking the limit as $w$ goes to 0, we get $\\sum^{i=j}_{i=1} y_i - x_i$ which is an extremely boring constant 0, since y and x both sum to 1.\n",
    "\n",
    "This is looking bad but we can keep going and look at more derivatives. Perhaps the second derivative will be a tiebreaker. \n",
    "\n",
    "The second derivative is $\\sum^{i=j}_{i=1} \\frac{x_i(y_i-x_i)^2}{(-wx_i+wy_i+x_i)^2}$. Taking the limit as $w$ approaches 0, we get $\\sum^{i=j}_{i=1} \\frac{(y_i-x_i)^2}{x_i}$, which is a well-behaved error metric! \n",
    "\n",
    "It is a weighted mean-squared-error, where each group is weighted by the inverse of its \"true\" value. We can rearrange it to $\\sum^{i=j}_{i=1} (y_i-x_i) * \\frac{(y_i-x_i)}{x_i}$ which shows that we are calculating the product of the proportional deviation and the absolute deviation for each group. This gives us the exact properties we wanted- with the proportion held equal, the group with the higher absolute deviation matters more, and with absolute deviation held equal, the group for which is it a higher percentage matters more. Plus, it is interpretable. We didn't just declare this as a metric because it has nice properties, we set it up as the answer to a meaningful question!\n",
    "\n",
    "We may be worried that this metric involves division, invoking the specter of divide-by-zero errors. However this will not happen becauase the denominator is $x_i$, and the frequency of all groups on the aggregate level must be greater than 0.\n",
    "\n",
    "Now let's try applying this new metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea3b2e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def inverse_weighted_mse(row):\n",
    "    #cosine_similarity = \n",
    "    return np.sum(((row.values[:7]-df_country_values)**2) / df_country_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05f5be5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zach Rosenof\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1676: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n"
     ]
    }
   ],
   "source": [
    "df_states.loc[:,['inverse_weighted_mse']] = df_states.apply(inverse_weighted_mse, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "baba5771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>corr</th>\n",
       "      <th>inverse_weighted_mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Illinois</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>Illinois</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>Connecticut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Connecticut</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>New Jersey</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>New Jersey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>Rhode Island</td>\n",
       "      <td>Rhode Island</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Florida</td>\n",
       "      <td>Florida</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>Massachusetts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Delaware</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>Florida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Rhode Island</td>\n",
       "      <td>Rhode Island</td>\n",
       "      <td>Kansas</td>\n",
       "      <td>Colorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Colorado</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>Nebraska</td>\n",
       "      <td>Virginia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>North Carolina</td>\n",
       "      <td>Washington</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>Kansas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>Washington</td>\n",
       "      <td>Nevada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Washington</td>\n",
       "      <td>Delaware</td>\n",
       "      <td>Utah</td>\n",
       "      <td>North Carolina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Pennsylvania</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Nevada</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>Arkansas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>Delaware</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               mae             mse           corr inverse_weighted_mse\n",
       "0         Illinois        Illinois       Illinois             Illinois\n",
       "1         New York        New York    Connecticut          Connecticut\n",
       "2      Connecticut     Connecticut       New York             New York\n",
       "3       New Jersey      New Jersey     New Jersey           New Jersey\n",
       "4         Virginia        Virginia   Rhode Island         Rhode Island\n",
       "5          Florida         Florida       Colorado        Massachusetts\n",
       "6         Delaware        Colorado  Massachusetts              Florida\n",
       "7     Rhode Island    Rhode Island         Kansas             Colorado\n",
       "8         Colorado  North Carolina       Nebraska             Virginia\n",
       "9   North Carolina      Washington   Pennsylvania               Kansas\n",
       "10   Massachusetts   Massachusetts     Washington               Nevada\n",
       "11      Washington        Delaware           Utah       North Carolina\n",
       "12        Arkansas        Oklahoma         Oregon         Pennsylvania\n",
       "13          Nevada        Arkansas       Arkansas             Arkansas\n",
       "14    Pennsylvania          Nevada       Virginia             Delaware"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'mae' : get_top_n(df_states,'mae',15), \n",
    "              'mse' : get_top_n(df_states,'mse',15), \n",
    "              'corr' : get_top_n(df_states,'corr',15),\n",
    "              'inverse_weighted_mse' : get_top_n(df_states,'inverse_weighted_mse',15),\n",
    "\n",
    "             })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf7409d",
   "metadata": {},
   "source": [
    "# 4. Conclusion\n",
    "\n",
    "The top four are still the same, which is not surprising. Those four match the country the best by a long shot. \n",
    "\n",
    "Below that, we get something that looks like a mixture of the other two lists. Virginia, for example, is number 5 by mae and mse, number 15 by correlation, and number 9 by our inverse_weighted_mse\n",
    "\n",
    "Also, if you are curious about the full ranking, here it is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "087f1544",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = pd.DataFrame({'Rank' : range(1,52)\n",
    "                 ,'State' : get_top_n(df_states,'inverse_weighted_mse',51)\n",
    "                 }).set_index('Rank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de4cafc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rank</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Illinois</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Connecticut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New Jersey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rhode Island</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Massachusetts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Florida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Colorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Virginia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Kansas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Nevada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>North Carolina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Pennsylvania</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Arkansas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Delaware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Washington</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Michigan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Oregon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Nebraska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Indiana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Tennessee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Minnesota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Wisconsin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Missouri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Ohio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Utah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Idaho</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Iowa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Kentucky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>South Carolina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Maryland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Wyoming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Texas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Georgia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>New Hampshire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Louisiana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>West Virginia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Vermont</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Maine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>North Dakota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Mississippi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Montana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Oklahoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>District of Columbia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>South Dakota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>New Mexico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Alaska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Puerto Rico</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     State\n",
       "Rank                      \n",
       "1                 Illinois\n",
       "2              Connecticut\n",
       "3                 New York\n",
       "4               New Jersey\n",
       "5             Rhode Island\n",
       "6            Massachusetts\n",
       "7                  Florida\n",
       "8                 Colorado\n",
       "9                 Virginia\n",
       "10                  Kansas\n",
       "11                  Nevada\n",
       "12          North Carolina\n",
       "13            Pennsylvania\n",
       "14                Arkansas\n",
       "15                Delaware\n",
       "16              Washington\n",
       "17                Michigan\n",
       "18                  Oregon\n",
       "19                Nebraska\n",
       "20                 Indiana\n",
       "21               Tennessee\n",
       "22               Minnesota\n",
       "23               Wisconsin\n",
       "24                Missouri\n",
       "25                    Ohio\n",
       "26                    Utah\n",
       "27                   Idaho\n",
       "28                    Iowa\n",
       "29                Kentucky\n",
       "30          South Carolina\n",
       "31                Maryland\n",
       "32                 Arizona\n",
       "33                 Wyoming\n",
       "34                   Texas\n",
       "35                 Alabama\n",
       "36                 Georgia\n",
       "37           New Hampshire\n",
       "38               Louisiana\n",
       "39           West Virginia\n",
       "40                 Vermont\n",
       "41                   Maine\n",
       "42              California\n",
       "43            North Dakota\n",
       "44             Mississippi\n",
       "45                 Montana\n",
       "46                Oklahoma\n",
       "47    District of Columbia\n",
       "48            South Dakota\n",
       "49              New Mexico\n",
       "50                  Alaska\n",
       "51             Puerto Rico"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90737876",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
